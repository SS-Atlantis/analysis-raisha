{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the sensitivity of SSAM output to small fluctuations in input\n",
    "Quantifying differences in the output files of Salish Sea Atlantis Model simulations with small differences in input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import ssam_groups as groups\n",
    "import ssam_plot as splot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_rmsd_percent(one, two):\n",
    "    one_all_layers = one.sum(axis=2)\n",
    "    two_all_layers = two.sum(axis=2)\n",
    "    diff = abs(one_all_layers-two_all_layers)\n",
    "    diff_ratio = diff/two_all_layers\n",
    "    diff_ratio_squared = diff_ratio**2\n",
    "    diff_ratio_squared1 = diff_ratio_squared.mean(axis=1, skipna=True)\n",
    "    diff_ratio_squared_mean = diff_ratio_squared1.mean(axis=0, skipna=True)\n",
    "    my_rmsd_percent = ((diff_ratio_squared_mean)**(1/2))*100\n",
    "    return my_rmsd_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_rmsd_percent_resampled(one, two):\n",
    "    one_all_layers = one.sum(dim='z')\n",
    "    two_all_layers = two.sum(dim='z')\n",
    "    diff = abs(one_all_layers-two_all_layers)\n",
    "    diff_ratio = diff/two_all_layers\n",
    "    diff_ratio_squared = diff_ratio**2\n",
    "    diff_ratio_squared1 = diff_ratio_squared.mean(dim='b', skipna=True)\n",
    "    diff_ratio_squared_mean = diff_ratio_squared1.mean(dim='t', skipna=True)\n",
    "    my_rmsd_percent_resampled = ((diff_ratio_squared_mean)**(1/2))*100\n",
    "    return my_rmsd_percent_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control_file = \"/ocean/rlovindeer/MOAD/analysis-raisha/SSmodel_outputs/Sensitivity/control/outputSalishSea.nc\"\n",
    "control_file = \"/ocean/rlovindeer/MOAD/analysis-raisha/SSmodel_outputs/Scrubber/Scrubber_discharge_100y_2029_latestart/outputSalishSea.nc\"\n",
    "control= xr.open_dataset(str(control_file), decode_cf=True)\n",
    "annual_control = control.resample(t='5Y').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_path = Path('/ocean/rlovindeer/MOAD/analysis-raisha/SSmodel_outputs/Scrubber/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking land boxes\n",
    "Temps = np.ma.filled(control.Temp[1,:,5], np.nonzero)\n",
    "(ocean_boxes) = Temps.nonzero()\n",
    "ocean_boxes = ocean_boxes[0]\n",
    "ocean_boxes = ocean_boxes[1:ocean_boxes.size-1]\n",
    "#ocean_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scrubber_discharge_100y_2024_latestart'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scens = sorted([p for p in scenario_path.glob('Scrubber_discharge_100y_2024*/outputSalishSea.nc')])\n",
    "for path in scens:\n",
    "    nm = str(path).split(sep = '/')\n",
    "    #name1 = nm[7].split(sep='_')\n",
    "    name = nm[7]\n",
    "name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process files with snapshot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_dict = {'BC', 'FHE', 'MA', 'ORR', 'PL', 'PS', 'WHB'}\n",
    "file_dict = {'MA', 'PS'}\n",
    "scens = sorted([p for p in scenario_path.glob('Scrubber_discharge_100y_2029/outputSalishSea.nc')])\n",
    "\n",
    "# measured opening of scenario files\n",
    "for path in scens:\n",
    "    nm = str(path).split(sep = '/')\n",
    "    name = nm[7]\n",
    "    #name1 = nm[7].split(sep='_')\n",
    "    #name = name1[1]\n",
    "\n",
    "    rmsd_data = pd.DataFrame({'scenario_file': [],\n",
    "                    'species': [],\n",
    "                    'RMSD%': []},)\n",
    "    scenario = xr.open_dataset(str(path), decode_cf=True)\n",
    "    for species in groups.all_pelagic:\n",
    "        one = control.variables[groups.all_pelagic[species] + '_N'][:][ocean_boxes]\n",
    "        two = scenario.variables[groups.all_pelagic[species] +'_N'][:][ocean_boxes]\n",
    "\n",
    "        rmsd_score = my_rmsd_percent(one, two)\n",
    "        rmsd_data.loc[len(rmsd_data.index)] = [name, species, float(rmsd_score)]                       \n",
    "    rmsd_data.to_csv(\"/ocean/rlovindeer/MOAD/analysis-raisha/SSmodel_outputs/Sensitivity/rmsd_percent_snapshot\"+name+\"_13Jul.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process files with 5-year resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_dict = {'BC', 'FHE', 'MA', 'ORR', 'PL', 'PS', 'WHB'}\n",
    "#file_dict = {'MA', 'PS'}\n",
    "\n",
    "#scens = sorted([p for p in scenario_path.glob('butterflyeffect_*x11/outputSalishSea.nc')])\n",
    "\n",
    "# measured opening of scenario files\n",
    "for path in scens:\n",
    "    nm = str(path).split(sep = '/')\n",
    "    name = nm[7]\n",
    "    #name1 = nm[7].split(sep='_')\n",
    "    #name = name1[1]\n",
    "\n",
    "    rmsd_data = pd.DataFrame({'scenario_file': [],\n",
    "                    'species': [],\n",
    "                    'RMSD%': []},)\n",
    "    scenario = xr.open_dataset(str(path), decode_cf=True)\n",
    "    annual_scenario = scenario.resample(t='5Y').mean()\n",
    "    for species in groups.all_pelagic:\n",
    "        two = annual_scenario.variables[groups.all_pelagic[species] +'_N'][:, ocean_boxes, :]\n",
    "        one = annual_control.variables[groups.all_pelagic[species] + '_N'][:, ocean_boxes, :]\n",
    "\n",
    "        rmsd_score = my_rmsd_percent_resampled(one, two)\n",
    "        rmsd_data.loc[len(rmsd_data.index)] = [name, species, float(rmsd_score)]                       \n",
    "    rmsd_data.to_csv(\"/ocean/rlovindeer/MOAD/analysis-raisha/SSmodel_outputs/Sensitivity/rmsd_percent_resampled\"+name+\"_13Jul.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4d84b090d0c7c6778fa197aacf5543338ee30c87f3fb579a323dc77be78ea57"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('parcels-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
