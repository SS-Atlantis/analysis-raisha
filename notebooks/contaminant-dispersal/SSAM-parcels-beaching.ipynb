{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b8d036b-e362-4a3f-a7cd-79fe1b26aa08",
   "metadata": {},
   "source": [
    "Testing surface oil beaching using [Parcels](https://oceanparcels.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e85ecd-0b24-4ae4-81a6-d9de3b6d88ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Compiled ParcelsRandom ==> /tmp/parcels-2926/libparcels_random_f9a26b53-3bdf-48b8-8c21-d42eaf5be75d.so\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from parcels import VectorField, Variable #AdvectionRK4\n",
    "from parcels import FieldSet, plotTrajectoriesFile, Variable, ScipyParticle, Field, ParcelsRandom\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "sys.path.append('/ocean/rlovindeer/Atlantis/ssam_oceanparcels/Parcels_Utils/particle_tracking/parcels/')\n",
    "from util.seed_particles import get_particles, get_release_times\n",
    "# from util.parse_wildcards import parse_wildcards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2125a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spill release times\n",
    "release_start_time = '2019-01-12'  ## winter start on December, Summer Jul - Aug  ## ask Susan about when to do simulation\n",
    "release_end_time = '2019-01-13'\n",
    "release_YYYY = '2019-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10cbc8d-88bf-42b7-a270-2d523e1a02fa",
   "metadata": {},
   "source": [
    "Select the location of interest, which is specified by a shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a25536-1e75-4dc0-8679-d4b81889f2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario running  : 5b_Turn_Point_Diluted_bitumen\n"
     ]
    }
   ],
   "source": [
    "file_id = int(input( ))\n",
    "scenario = {1 : \"5b_Turn_Point_Diluted_bitumen\",\n",
    "            2 : \"6a_VancouverHarbour_BunkerC\",\n",
    "            3 : \"7a_JStrait_BunkerC\",\n",
    "            4 : \"4a_ActivePass_Diesel\",\n",
    "            5 : \"SandHeads\"}\n",
    "print(\"\\nScenario running  :\", scenario[file_id], sep = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34fdf25b-955c-4553-ac0c-930a86217905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kernels\n",
    "\n",
    "def AdvectionRK4(particle, fieldset, time):\n",
    "    \"\"\"Advection of particles using fourth-order Runge-Kutta integration.\n",
    "    Function needs to be converted to Kernel object before execution\"\"\"\n",
    "    if particle.beached == 0:\n",
    "        (u1, v1) = fieldset.UV[particle]\n",
    "        lon1, lat1 = (particle.lon + u1*.5*particle.dt, particle.lat + v1*.5*particle.dt)\n",
    "        (u2, v2) = fieldset.UV[time + .5 * particle.dt, particle.depth, lat1, lon1, particle]\n",
    "        lon2, lat2 = (particle.lon + u2*.5*particle.dt, particle.lat + v2*.5*particle.dt)\n",
    "        (u3, v3) = fieldset.UV[time + .5 * particle.dt, particle.depth, lat2, lon2, particle]\n",
    "        lon3, lat3 = (particle.lon + u3*particle.dt, particle.lat + v3*particle.dt)\n",
    "        (u4, v4) = fieldset.UV[time + particle.dt, particle.depth, lat3, lon3, particle]\n",
    "        particle.lon += (u1 + 2*u2 + 2*u3 + u4) / 6. * particle.dt\n",
    "        particle.lat += (v1 + 2*v2 + 2*v3 + v4) / 6. * particle.dt\n",
    "    \n",
    "def WindAdvectionRK4(particle, fieldset, time):\n",
    "    \"\"\"Advection of particles using fourth-order Runge-Kutta integration.\n",
    "     Function needs to be converted to Kernel object before execution\"\"\"\n",
    "    if particle.beached == 0:\n",
    "        wp = fieldset.wind_percentage ## this need to be add to the fieldset\n",
    "        \n",
    "        if wp > 0:\n",
    "\n",
    "            (u1, v1) = fieldset.UVwind[time, particle.depth, particle.lat, particle.lon]\n",
    "            u1 = u1 * wp\n",
    "            v1 = v1 * wp\n",
    "            lon1, lat1 = (particle.lon + u1*.5*particle.dt, particle.lat + v1*.5*particle.dt)\n",
    "            \n",
    "            (u2, v2) = fieldset.UVwind[time + .5 * particle.dt, particle.depth, lat1, lon1]\n",
    "            u2 = u2 * wp\n",
    "            v2 = v2 * wp\n",
    "            lon2, lat2 = (particle.lon + u2*.5*particle.dt, particle.lat + v2*.5*particle.dt)\n",
    "            \n",
    "            (u3, v3) = fieldset.UVwind[time + .5 * particle.dt, particle.depth, lat2, lon2]\n",
    "            u3 = u3 * wp\n",
    "            v3 = v3 * wp\n",
    "            lon3, lat3 = (particle.lon + u3*particle.dt, particle.lat + v3*particle.dt)\n",
    "            \n",
    "            (u4, v4) = fieldset.UVwind[time + particle.dt, particle.depth, lat3, lon3]\n",
    "            u4 = u4 * wp\n",
    "            v4 = v4 * wp            \n",
    "            \n",
    "            u_wind  = (u1 + 2*u2 + 2*u3 + u4) / 6. * particle.dt\n",
    "            v_wind  = (v1 + 2*v2 + 2*v3 + v4) / 6. * particle.dt\n",
    "            \n",
    "            particle.lon += (u1 + 2*u2 + 2*u3 + u4) / 6. * particle.dt\n",
    "            particle.lat += (v1 + 2*v2 + 2*v3 + v4) / 6. * particle.dt\n",
    "            \n",
    "            particle.beached = 2\n",
    "\n",
    "def beaching(particle, fieldset, time):\n",
    "    \n",
    "    if particle.beached == 2:\n",
    "        \n",
    "        # Parameters\n",
    "        deg2m = 111000     # [m/deg]\n",
    "        D = 50   # maximum beaching distance [m]\n",
    "        \n",
    "        # Grounding probability over radius D\n",
    "        offset_lon = random.uniform(-1., 1.) * D / deg2m\n",
    "        offset_lat = random.uniform(-1., 1.) * D / deg2m\n",
    "\n",
    "        # Evaluate if chosen point is over land\n",
    "        (u, v) = fieldset.UV[time, particle.depth, particle.lat + offset_lat, particle.lon + offset_lon]\n",
    "        if u == 0 and v == 0: \n",
    "            particle.beached = 1\n",
    "        else:\n",
    "            particle.beached = 0\n",
    "\n",
    "def DeleteParticle(particle, fieldset, time):\n",
    "    particle.delete()\n",
    "\n",
    "def DecayParticle(particle, fieldset, time):\n",
    "    dt = particle.dt\n",
    "    field_decay_value = fieldset.decay\n",
    "    decay = math.exp(0 * dt/field_decay_value) # -0.099 for diesel, 0 for other oils\n",
    "    particle.decay_value = particle.decay_value * decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c19fb9-3acc-442e-b1ea-62bcf5a3fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Paths\n",
    "currents = Path('/ocean/rlovindeer/Atlantis/Physics/Raw_Transport_Data/')\n",
    "winds = Path('/ocean/rlovindeer/Atlantis/Physics/Wind/')\n",
    "sea_grid = Path('/ocean/rlovindeer/Atlantis/Physics/Grids/ubcSSnBathymetryV17-02_a29d_efc9_4047.nc')\n",
    "air_grid = Path('/ocean/rlovindeer/Atlantis/Physics/Grids/ubcSSaAtmosphereGridV1_0f03_6268_df4b.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62049698-848c-46a5-a4da-4fb6de91df61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Casting lon data to np.float32\n",
      "WARNING: Casting lat data to np.float32\n",
      "WARNING: Casting depth data to np.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating from_nemo\n",
      "creating from_nemo done\n",
      "add_constant decay\n"
     ]
    }
   ],
   "source": [
    "# Salish Sea NEMO Model Grid, Geo-location and Bathymetry, v17-02\n",
    "\n",
    "# Currents\n",
    "# u_data_path = currents + '2018-01*URaw_variables.nc'\n",
    "# v_data_path = currents + '2018-01*VRaw_variables.nc'\n",
    "# u_current = parse_wildcards(u_data_path, 'u')\n",
    "# v_current = parse_wildcards(v_data_path, 'v')\n",
    "\n",
    "u_current = sorted([p for p in currents.glob(str(release_YYYY) + '*URaw_variables.nc')])\n",
    "v_current = sorted([p for p in currents.glob(str(release_YYYY) + '*VRaw_variables.nc')])\n",
    "\n",
    "filenames = {\n",
    "    'U': {'lon': sea_grid,'lat': sea_grid,'data': u_current},\n",
    "    'V': {'lon': sea_grid,'lat': sea_grid,'data': v_current}\n",
    "            }\n",
    "\n",
    "variables = {'U': 'uVelocity','V': 'vVelocity'}\n",
    "dimensions = {'lon': 'longitude', 'lat': 'latitude', 'time': 'time'}\n",
    "print('creating from_nemo')\n",
    "fieldset = FieldSet.from_nemo(filenames, variables, dimensions, allow_time_extrapolation=True)\n",
    "print('creating from_nemo done')\n",
    "\n",
    "fieldset.add_constant('decay', 1.0 * 3600.0)\n",
    "print('add_constant decay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d71250-4e60-47bd-8cbb-12c2b538d61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [PosixPath('/ocean/rlovindeer/Atlantis/Physics/Wind/2019-01-01_Wind_variables.nc'),\n",
      "          PosixPath('/ocean/rlovindeer/Atlantis/Physics/Wind/2019-01-07_Wind_variables.nc'),\n",
      "          PosixPath('/ocean/rlovindeer/Atlantis/Physics/Wind/2019-01-13_Wind_variables.nc'),\n",
      "          PosixPath('/ocean/rlovindeer/Atlantis/Physics/Wind/2019-01-19_Wind_variables.nc'),\n",
      "          PosixPath('/ocean/rlovindeer/Atlantis/Physics/Wind/2019-01-25_Wind_variables.nc'),\n",
      "          PosixPath('/ocean/rlovindeer/Atlantis/Physics/Wind/2019-01-31_Wind_variables.nc')],\n",
      " 'lat': '/ocean/rlovindeer/Atlantis/Physics/Grids/ubcSSaAtmosphereGridV1_0f03_6268_df4b.nc',\n",
      " 'lon': '/ocean/rlovindeer/Atlantis/Physics/Grids/ubcSSaAtmosphereGridV1_0f03_6268_df4b.nc'}\n"
     ]
    }
   ],
   "source": [
    "# HRDPS, Salish Sea, Atmospheric Forcing Grid, Geo-location, v1\"\n",
    "\n",
    "wind_paths = sorted([p for p in winds.glob(str(release_YYYY) + '*Wind_variables.nc')])\n",
    "wind_filenames = {'lon': os.fspath(air_grid),'lat': os.fspath(air_grid),'data': wind_paths}\n",
    "wind_dimensions = {'lon': 'longitude', 'lat': 'latitude', 'time': 'time'}\n",
    "\n",
    "pprint(wind_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7a4b014-1f05-4dc8-9f4c-2a65f51d0df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind data loaded\n"
     ]
    }
   ],
   "source": [
    "Uwind_field = Field.from_netcdf(wind_filenames, ('U_wind', 'u_wind'),\n",
    "                                     wind_dimensions,\n",
    "                                     fieldtype='U',\n",
    "                                     allow_time_extrapolation=True,\n",
    "                                     transpose=False,\n",
    "                                     deferred_load=False)\n",
    "Vwind_field = Field.from_netcdf(wind_filenames, ('V_wind', 'v_wind'),\n",
    "                                     wind_dimensions,\n",
    "                                     fieldtype='V',\n",
    "                                     allow_time_extrapolation=True,\n",
    "                                     transpose=False,\n",
    "                                     deferred_load=False)\n",
    "\n",
    "print('wind data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37823b69-6440-49f1-a693-4b75a263b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change longitude for the wind field\n",
    "Uwind_field.grid.lon = Uwind_field.grid.lon - 360\n",
    "Vwind_field.grid.lon = Vwind_field.grid.lon - 360\n",
    "\n",
    "[x_min, x_max, y_min, y_max] = Uwind_field.grid.lonlat_minmax\n",
    "\n",
    "Uwind_field.grid.lonlat_minmax = [x_min - 360, x_max - 360, y_min, y_max]\n",
    "Vwind_field.grid.lonlat_minmax = [x_min - 360, x_max - 360, y_min, y_max]\n",
    "\n",
    "## adding the wind field to the fieldset object\n",
    "fieldset.add_field(Uwind_field)\n",
    "fieldset.add_field(Vwind_field)\n",
    "wind_field = VectorField('UVwind', Uwind_field,  Vwind_field)\n",
    "fieldset.add_vector_field(wind_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b661e048-885d-492e-97c0-64fe19327be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind_percentage\n",
    "# We need to do a sensitivity analysis of the percetage of wind to be used here\n",
    "wind_percentage = 3 #should this be 3?\n",
    "fieldset.add_constant('wind_percentage', wind_percentage/100.0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f50b40f-3404-4c6e-abfb-0406dbb85b25",
   "metadata": {},
   "source": [
    "Just in case we want to add a maximum age\n",
    "# fieldset_sum.add_constant('max_age', dispersal_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927c988b-bba4-4231-812b-6948bb407bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up particles\n",
      "689400.0\n",
      "100\n",
      "100\n",
      "Using shapefile /ocean/rlovindeer/Atlantis/ssam_oceanparcels/SalishSea/Shape_Scenarios/5b_Turn_Point_Diluted_bitumen.shp\n",
      "Number of sites :  1\n",
      "Up to 0 of 1\n",
      "80\n",
      "100\n",
      "Sucessfully seeded particles\n",
      "\n",
      "num_attempts = 2\n",
      "[-123.29342181743614, -123.29308906571126, -123.29331391769186, -123.29342967807801, -123.29367213484532, -123.29322765621787, -123.29364427002147, -123.29273589844243, -123.29375256140635, -123.29293599436784, -123.2934616546045, -123.29338335532181, -123.29266825116741, -123.2943451858446, -123.2928542047529, -123.2929631309421, -123.29277942014751, -123.29292112731557, -123.29359648571949, -123.29295838609143, -123.29428289559226, -123.29323960240134, -123.29263010660989, -123.2934757478005, -123.29369012056402, -123.2939903332198, -123.29297097706512, -123.29360714377957, -123.29338257654626, -123.29448186484314, -123.29328417344985, -123.29329525299856, -123.29328557645024, -123.29263194828697, -123.29315580384579, -123.29380042864285, -123.2936453805364, -123.29312418205214, -123.29318591101311, -123.29317816870477, -123.29409867932186, -123.29388858774216, -123.29337905090317, -123.29364224141707, -123.29431535482252, -123.29410169093181, -123.29419682540824, -123.29321322779307, -123.29401286123893, -123.29358682289829, -123.29420150527672, -123.29429869416168, -123.29320678526507, -123.29378199410269, -123.29432524189242, -123.292843554629, -123.29256652551398, -123.2935821420407, -123.29330975340451, -123.2930409172852, -123.29395383051884, -123.29392716404895, -123.29388347808522, -123.29369091845497, -123.29439114945131, -123.29313450020526, -123.29338624153559, -123.29398866546212, -123.29347294833707, -123.29433156342249, -123.29336755145289, -123.29266085204884, -123.2938823065391, -123.29318462368407, -123.2942558487192, -123.29308679003576, -123.29394063225811, -123.29415306172, -123.29334641857439, -123.29451005349162, -123.29389585268001, -123.29312675746637, -123.29376394076542, -123.29447008698722, -123.29316065889701, -123.29361205075489, -123.29344628602179, -123.29408565047521, -123.2931932880378, -123.29399279969053, -123.29300268713632, -123.29387941014235, -123.29375251665566, -123.2933428102169, -123.29285734753353, -123.29326148075681, -123.29397236037437, -123.29292335077618, -123.2941481725554, -123.29261386113005]\n",
      "5b_Turn_Point_Diluted_bitumen2019-01-12_OP_D50_wp3.nc\n"
     ]
    }
   ],
   "source": [
    "class MyParticle(ScipyParticle):\n",
    "    initial_time = -100\n",
    "    decay_value = Variable('decay_value', dtype=np.float32, initial=1.0)\n",
    "    beached = Variable('beached', dtype=np.int32, initial=0.)\n",
    "    age = Variable('age', dtype=np.int32, initial=0.)\n",
    "\n",
    "# Particle Features\n",
    "num_particles_per_day = 100\n",
    "feature_release_index = 0\n",
    "input_shapefile_name = \"/ocean/rlovindeer/Atlantis/ssam_oceanparcels/SalishSea/Shape_Scenarios/\" + scenario[file_id] + \".shp\"\n",
    "release_depth = -0.1\n",
    "release_start_time = np.datetime64(release_start_time)\n",
    "release_end_time = np.datetime64(release_end_time)\n",
    "time_origin = fieldset.U.grid.time_origin.time_origin\n",
    "\n",
    "print('setting up particles')\n",
    "\n",
    "[release_times, p, num_particles] = get_release_times(time_origin, num_particles_per_day, release_start_time, release_end_time)\n",
    "pset = get_particles(fieldset, num_particles, input_shapefile_name, MyParticle, feature_release_index, release_times, release_depth)\n",
    "\n",
    "#print(pset)\n",
    "\n",
    "# Building the kernels\n",
    "decay_kernel = pset.Kernel(DecayParticle)\n",
    "beaching_kernel = pset.Kernel(beaching)\n",
    "ForcingWind_kernel = pset.Kernel(WindAdvectionRK4)\n",
    "Advection_kernel = pset.Kernel(AdvectionRK4)\n",
    "\n",
    "# Adding to the main kernel\n",
    "my_kernel = Advection_kernel + decay_kernel + ForcingWind_kernel + beaching_kernel\n",
    "\n",
    "output_file_name = scenario[file_id] + str(release_start_time) +  '_OP_D50_wp3.nc'\n",
    "print(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95d50dee-2c5a-496c-ab9c-798b1e31f8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing particle kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '5b_Turn_Point_Diluted_bitumen2019-01-12_OP_D50_wp3.nc': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.system('rm ' + output_file_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print('executing particle kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca91b311-7297-479d-b17e-484906a1b675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Temporary output files are stored in out-DLRCUQYY.\n",
      "INFO: You can use \"parcels_convert_npydir_to_netcdf out-DLRCUQYY\" to convert these to a NetCDF file during the run.\n",
      "N/A% (0 of 604800.0) |                   | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      "  4% (25200.0 of 604800.0) |             | Elapsed Time: 0:00:02 ETA:   0:00:57\n",
      "  4% (28800.0 of 604800.0) |             | Elapsed Time: 0:00:07 ETA:   0:14:26\n",
      "  5% (32400.0 of 604800.0) |             | Elapsed Time: 0:00:13 ETA:   0:13:44\n",
      "  5% (36000.0 of 604800.0) |             | Elapsed Time: 0:00:18 ETA:   0:14:35\n",
      "  6% (39600.0 of 604800.0) |             | Elapsed Time: 0:00:24 ETA:   0:15:15\n",
      "  7% (43200.0 of 604800.0) |             | Elapsed Time: 0:00:30 ETA:   0:16:15\n",
      "  7% (44400.0 of 604800.0) |             | Elapsed Time: 0:00:32 ETA:   0:17:36\n",
      "  7% (45000.0 of 604800.0) |             | Elapsed Time: 0:00:34 ETA:   0:19:41\n",
      "  7% (46800.0 of 604800.0) |#            | Elapsed Time: 0:00:38 ETA:   0:21:44\n",
      "  8% (50400.0 of 604800.0) |#            | Elapsed Time: 0:00:47 ETA:   0:23:18\n",
      "  8% (54000.0 of 604800.0) |#            | Elapsed Time: 0:00:56 ETA:   0:21:48\n",
      "  9% (57600.0 of 604800.0) |#            | Elapsed Time: 0:01:05 ETA:   0:23:27\n",
      " 10% (61200.0 of 604800.0) |#            | Elapsed Time: 0:01:14 ETA:   0:22:18\n",
      " 10% (64800.0 of 604800.0) |#            | Elapsed Time: 0:01:24 ETA:   0:24:19\n",
      " 10% (66000.0 of 604800.0) |#            | Elapsed Time: 0:01:27 ETA:   0:26:59\n",
      " 11% (66600.0 of 604800.0) |#            | Elapsed Time: 0:01:30 ETA:   0:33:05\n",
      " 11% (68400.0 of 604800.0) |#            | Elapsed Time: 0:01:36 ETA:   0:30:53\n",
      " 11% (72000.0 of 604800.0) |#            | Elapsed Time: 0:01:50 ETA:   0:34:08\n",
      " 12% (75600.0 of 604800.0) |#            | Elapsed Time: 0:02:04 ETA:   0:35:41\n",
      " 13% (79200.0 of 604800.0) |#            | Elapsed Time: 0:02:20 ETA:   0:37:24\n",
      " 13% (82800.0 of 604800.0) |#            | Elapsed Time: 0:02:36 ETA:   0:38:56\n",
      " 14% (86400.0 of 604800.0) |#            | Elapsed Time: 0:02:52 ETA:   0:39:51\n",
      " 14% (87600.0 of 604800.0) |#            | Elapsed Time: 0:02:58 ETA:   0:41:25\n",
      " 14% (88200.0 of 604800.0) |#            | Elapsed Time: 0:03:01 ETA:   0:49:19\n",
      " 14% (90000.0 of 604800.0) |#            | Elapsed Time: 0:03:11 ETA:   0:43:20\n",
      " 15% (93600.0 of 604800.0) |##           | Elapsed Time: 0:03:30 ETA:   0:47:03\n",
      " 16% (97200.0 of 604800.0) |##           | Elapsed Time: 0:03:51 ETA:   0:48:13\n",
      " 16% (100800.0 of 604800.0) |##          | Elapsed Time: 0:04:12 ETA:   0:48:43\n",
      " 17% (104400.0 of 604800.0) |##          | Elapsed Time: 0:04:33 ETA:   0:49:27\n",
      " 17% (108000.0 of 604800.0) |##          | Elapsed Time: 0:04:55 ETA:   0:50:05\n",
      " 18% (109200.0 of 604800.0) |##          | Elapsed Time: 0:05:02 ETA:   0:50:41\n",
      " 18% (109800.0 of 604800.0) |##          | Elapsed Time: 0:05:06 ETA:   0:51:01\n",
      " 18% (111600.0 of 604800.0) |##          | Elapsed Time: 0:05:16 ETA:   0:46:57\n",
      " 19% (115200.0 of 604800.0) |##          | Elapsed Time: 0:05:39 ETA:   0:50:25\n",
      " 19% (118800.0 of 604800.0) |##          | Elapsed Time: 0:06:01 ETA:   0:50:41\n",
      " 20% (122400.0 of 604800.0) |##          | Elapsed Time: 0:06:24 ETA:   0:50:18\n",
      " 20% (126000.0 of 604800.0) |##          | Elapsed Time: 0:06:45 ETA:   0:47:30\n",
      " 21% (129600.0 of 604800.0) |##          | Elapsed Time: 0:07:06 ETA:   0:45:04\n",
      " 21% (130800.0 of 604800.0) |##          | Elapsed Time: 0:07:11 ETA:   0:38:08\n",
      " 21% (131400.0 of 604800.0) |##          | Elapsed Time: 0:07:14 ETA:   0:39:33\n",
      " 22% (133200.0 of 604800.0) |##          | Elapsed Time: 0:07:22 ETA:   0:34:05\n",
      " 22% (136800.0 of 604800.0) |##          | Elapsed Time: 0:07:37 ETA:   0:33:08\n",
      " 23% (140400.0 of 604800.0) |##          | Elapsed Time: 0:07:52 ETA:   0:31:06\n",
      " 23% (144000.0 of 604800.0) |##          | Elapsed Time: 0:08:05 ETA:   0:28:22\n",
      " 24% (147600.0 of 604800.0) |##          | Elapsed Time: 0:08:16 ETA:   0:23:12\n",
      " 25% (151200.0 of 604800.0) |###         | Elapsed Time: 0:08:25 ETA:   0:18:30\n",
      " 25% (152400.0 of 604800.0) |###         | Elapsed Time: 0:08:28 ETA:   0:18:05\n",
      " 25% (153000.0 of 604800.0) |###         | Elapsed Time: 0:08:29 ETA:   0:18:24\n",
      " 25% (154800.0 of 604800.0) |###         | Elapsed Time: 0:08:33 ETA:   0:16:40\n",
      " 26% (158400.0 of 604800.0) |###         | Elapsed Time: 0:08:42 ETA:   0:18:32\n",
      " 26% (162000.0 of 604800.0) |###         | Elapsed Time: 0:08:51 ETA:   0:18:37\n",
      " 27% (165600.0 of 604800.0) |###         | Elapsed Time: 0:09:01 ETA:   0:18:49\n",
      " 27% (169200.0 of 604800.0) |###         | Elapsed Time: 0:09:10 ETA:   0:19:14\n",
      " 28% (172800.0 of 604800.0) |###         | Elapsed Time: 0:09:20 ETA:   0:19:13\n",
      " 28% (174000.0 of 604800.0) |###         | Elapsed Time: 0:09:23 ETA:   0:19:03\n",
      " 28% (174600.0 of 604800.0) |###         | Elapsed Time: 0:09:25 ETA:   0:19:15\n",
      " 29% (176400.0 of 604800.0) |###         | Elapsed Time: 0:09:29 ETA:   0:17:38\n",
      " 29% (180000.0 of 604800.0) |###         | Elapsed Time: 0:09:39 ETA:   0:19:02\n",
      " 30% (183600.0 of 604800.0) |###         | Elapsed Time: 0:09:49 ETA:   0:18:55\n",
      " 30% (187200.0 of 604800.0) |###         | Elapsed Time: 0:09:58 ETA:   0:18:51\n",
      " 31% (190800.0 of 604800.0) |###         | Elapsed Time: 0:10:07 ETA:   0:17:14\n",
      " 32% (194400.0 of 604800.0) |###         | Elapsed Time: 0:10:16 ETA:   0:16:45\n",
      " 32% (195600.0 of 604800.0) |###         | Elapsed Time: 0:10:19 ETA:   0:16:42\n",
      " 32% (196200.0 of 604800.0) |###         | Elapsed Time: 0:10:21 ETA:   0:17:16\n",
      " 32% (198000.0 of 604800.0) |###         | Elapsed Time: 0:10:25 ETA:   0:15:12\n",
      " 33% (201600.0 of 604800.0) |####        | Elapsed Time: 0:10:34 ETA:   0:16:24\n",
      " 33% (205200.0 of 604800.0) |####        | Elapsed Time: 0:10:42 ETA:   0:16:14\n",
      " 34% (208800.0 of 604800.0) |####        | Elapsed Time: 0:10:51 ETA:   0:16:33\n",
      " 35% (212400.0 of 604800.0) |####        | Elapsed Time: 0:11:00 ETA:   0:16:23\n",
      " 35% (216000.0 of 604800.0) |####        | Elapsed Time: 0:11:09 ETA:   0:16:18\n",
      " 35% (217200.0 of 604800.0) |####        | Elapsed Time: 0:11:12 ETA:   0:16:15\n",
      " 36% (217800.0 of 604800.0) |####        | Elapsed Time: 0:11:14 ETA:   0:16:41\n",
      " 36% (219600.0 of 604800.0) |####        | Elapsed Time: 0:11:18 ETA:   0:14:45\n",
      " 36% (223200.0 of 604800.0) |####        | Elapsed Time: 0:11:27 ETA:   0:15:40\n",
      " 37% (226800.0 of 604800.0) |####        | Elapsed Time: 0:11:36 ETA:   0:15:54\n",
      " 38% (230400.0 of 604800.0) |####        | Elapsed Time: 0:11:45 ETA:   0:15:36\n",
      " 38% (234000.0 of 604800.0) |####        | Elapsed Time: 0:11:54 ETA:   0:15:29\n",
      " 39% (237600.0 of 604800.0) |####        | Elapsed Time: 0:12:03 ETA:   0:15:31\n",
      " 39% (238800.0 of 604800.0) |####        | Elapsed Time: 0:12:06 ETA:   0:15:25\n",
      " 39% (239400.0 of 604800.0) |####        | Elapsed Time: 0:12:08 ETA:   0:15:33\n",
      " 39% (241200.0 of 604800.0) |####        | Elapsed Time: 0:12:12 ETA:   0:14:14\n",
      " 40% (244800.0 of 604800.0) |####        | Elapsed Time: 0:12:21 ETA:   0:15:08\n",
      " 41% (248400.0 of 604800.0) |####        | Elapsed Time: 0:12:30 ETA:   0:15:14\n",
      " 41% (252000.0 of 604800.0) |#####       | Elapsed Time: 0:12:40 ETA:   0:15:15\n",
      " 42% (255600.0 of 604800.0) |#####       | Elapsed Time: 0:12:49 ETA:   0:15:06\n",
      " 42% (259200.0 of 604800.0) |#####       | Elapsed Time: 0:12:59 ETA:   0:15:08\n",
      " 43% (260400.0 of 604800.0) |#####       | Elapsed Time: 0:13:02 ETA:   0:15:13\n",
      " 43% (261000.0 of 604800.0) |#####       | Elapsed Time: 0:13:03 ETA:   0:15:13\n",
      " 43% (262800.0 of 604800.0) |#####       | Elapsed Time: 0:13:08 ETA:   0:13:35\n",
      " 44% (266400.0 of 604800.0) |#####       | Elapsed Time: 0:13:17 ETA:   0:14:39\n",
      " 44% (270000.0 of 604800.0) |#####       | Elapsed Time: 0:13:27 ETA:   0:14:43\n",
      " 45% (273600.0 of 604800.0) |#####       | Elapsed Time: 0:13:36 ETA:   0:14:38\n",
      " 45% (277200.0 of 604800.0) |#####       | Elapsed Time: 0:13:46 ETA:   0:14:19\n",
      " 46% (280800.0 of 604800.0) |#####       | Elapsed Time: 0:13:55 ETA:   0:14:14\n",
      " 46% (282000.0 of 604800.0) |#####       | Elapsed Time: 0:13:58 ETA:   0:14:11\n",
      " 46% (282600.0 of 604800.0) |#####       | Elapsed Time: 0:14:00 ETA:   0:14:18\n",
      " 47% (284400.0 of 604800.0) |#####       | Elapsed Time: 0:14:04 ETA:   0:13:01\n",
      " 47% (288000.0 of 604800.0) |#####       | Elapsed Time: 0:14:14 ETA:   0:13:50\n",
      " 48% (291600.0 of 604800.0) |#####       | Elapsed Time: 0:14:23 ETA:   0:13:53\n",
      " 48% (295200.0 of 604800.0) |#####       | Elapsed Time: 0:14:33 ETA:   0:13:38\n",
      " 49% (298800.0 of 604800.0) |#####       | Elapsed Time: 0:14:42 ETA:   0:13:42\n",
      " 50% (302400.0 of 604800.0) |######      | Elapsed Time: 0:14:52 ETA:   0:13:31\n",
      " 50% (303600.0 of 604800.0) |######      | Elapsed Time: 0:14:56 ETA:   0:14:47\n",
      " 50% (304200.0 of 604800.0) |######      | Elapsed Time: 0:14:58 ETA:   0:15:10\n",
      " 50% (306000.0 of 604800.0) |######      | Elapsed Time: 0:15:03 ETA:   0:15:18\n",
      " 51% (309600.0 of 604800.0) |######      | Elapsed Time: 0:15:13 ETA:   0:14:01\n",
      " 51% (313200.0 of 604800.0) |######      | Elapsed Time: 0:15:23 ETA:   0:13:03\n",
      " 52% (316800.0 of 604800.0) |######      | Elapsed Time: 0:15:33 ETA:   0:13:00\n",
      " 52% (320400.0 of 604800.0) |######      | Elapsed Time: 0:15:42 ETA:   0:12:42\n",
      " 53% (324000.0 of 604800.0) |######      | Elapsed Time: 0:15:52 ETA:   0:12:28\n",
      " 53% (325200.0 of 604800.0) |######      | Elapsed Time: 0:15:55 ETA:   0:12:27\n",
      " 53% (325800.0 of 604800.0) |######      | Elapsed Time: 0:15:57 ETA:   0:12:33\n",
      " 54% (327600.0 of 604800.0) |######      | Elapsed Time: 0:16:01 ETA:   0:11:19\n",
      " 54% (331200.0 of 604800.0) |######      | Elapsed Time: 0:16:11 ETA:   0:12:21\n",
      " 55% (334800.0 of 604800.0) |######      | Elapsed Time: 0:16:21 ETA:   0:12:10\n",
      " 55% (338400.0 of 604800.0) |######      | Elapsed Time: 0:16:30 ETA:   0:11:55\n",
      " 56% (342000.0 of 604800.0) |######      | Elapsed Time: 0:16:40 ETA:   0:11:49\n",
      " 57% (345600.0 of 604800.0) |######      | Elapsed Time: 0:16:50 ETA:   0:11:24\n",
      " 57% (346800.0 of 604800.0) |######      | Elapsed Time: 0:16:53 ETA:   0:11:21\n",
      " 57% (347400.0 of 604800.0) |######      | Elapsed Time: 0:16:54 ETA:   0:11:18\n",
      " 57% (349200.0 of 604800.0) |######      | Elapsed Time: 0:16:59 ETA:   0:10:22\n",
      " 58% (352800.0 of 604800.0) |#######     | Elapsed Time: 0:17:08 ETA:   0:11:02\n",
      " 58% (356400.0 of 604800.0) |#######     | Elapsed Time: 0:17:18 ETA:   0:11:04\n",
      " 59% (360000.0 of 604800.0) |#######     | Elapsed Time: 0:17:30 ETA:   0:13:07\n",
      " 60% (363600.0 of 604800.0) |#######     | Elapsed Time: 0:17:39 ETA:   0:10:48\n",
      " 60% (367200.0 of 604800.0) |#######     | Elapsed Time: 0:17:49 ETA:   0:11:11\n",
      " 60% (368400.0 of 604800.0) |#######     | Elapsed Time: 0:17:53 ETA:   0:12:46\n",
      " 61% (369000.0 of 604800.0) |#######     | Elapsed Time: 0:17:55 ETA:   0:12:16\n",
      " 61% (370800.0 of 604800.0) |#######     | Elapsed Time: 0:18:00 ETA:   0:10:52\n",
      " 61% (374400.0 of 604800.0) |#######     | Elapsed Time: 0:18:10 ETA:   0:11:04\n",
      " 62% (378000.0 of 604800.0) |#######     | Elapsed Time: 0:18:20 ETA:   0:10:09\n",
      " 63% (381600.0 of 604800.0) |#######     | Elapsed Time: 0:18:30 ETA:   0:09:56\n",
      " 63% (385200.0 of 604800.0) |#######     | Elapsed Time: 0:18:39 ETA:   0:09:43\n",
      " 64% (388800.0 of 604800.0) |#######     | Elapsed Time: 0:18:49 ETA:   0:09:27\n",
      " 64% (390000.0 of 604800.0) |#######     | Elapsed Time: 0:18:52 ETA:   0:09:16\n",
      " 64% (390600.0 of 604800.0) |#######     | Elapsed Time: 0:18:53 ETA:   0:09:18\n",
      " 64% (392400.0 of 604800.0) |#######     | Elapsed Time: 0:18:58 ETA:   0:08:26\n",
      " 65% (396000.0 of 604800.0) |#######     | Elapsed Time: 0:19:07 ETA:   0:08:58\n",
      " 66% (399600.0 of 604800.0) |#######     | Elapsed Time: 0:19:16 ETA:   0:08:54\n",
      " 66% (403200.0 of 604800.0) |########    | Elapsed Time: 0:19:26 ETA:   0:08:33\n",
      " 67% (406800.0 of 604800.0) |########    | Elapsed Time: 0:19:35 ETA:   0:08:21\n",
      " 67% (410400.0 of 604800.0) |########    | Elapsed Time: 0:19:44 ETA:   0:08:17\n",
      " 68% (411600.0 of 604800.0) |########    | Elapsed Time: 0:19:47 ETA:   0:08:19\n",
      " 68% (412200.0 of 604800.0) |########    | Elapsed Time: 0:19:49 ETA:   0:08:19\n",
      " 68% (414000.0 of 604800.0) |########    | Elapsed Time: 0:19:53 ETA:   0:07:21\n",
      " 69% (417600.0 of 604800.0) |########    | Elapsed Time: 0:20:02 ETA:   0:07:54\n",
      " 69% (421200.0 of 604800.0) |########    | Elapsed Time: 0:20:11 ETA:   0:07:40\n",
      " 70% (424800.0 of 604800.0) |########    | Elapsed Time: 0:20:20 ETA:   0:07:27\n",
      " 70% (428400.0 of 604800.0) |########    | Elapsed Time: 0:20:29 ETA:   0:07:15\n",
      " 71% (432000.0 of 604800.0) |########    | Elapsed Time: 0:20:38 ETA:   0:07:04\n",
      " 71% (433200.0 of 604800.0) |########    | Elapsed Time: 0:20:40 ETA:   0:06:53\n",
      " 71% (433800.0 of 604800.0) |########    | Elapsed Time: 0:20:42 ETA:   0:06:53\n",
      " 72% (435600.0 of 604800.0) |########    | Elapsed Time: 0:20:46 ETA:   0:06:22\n",
      " 72% (439200.0 of 604800.0) |########    | Elapsed Time: 0:20:55 ETA:   0:06:34\n",
      " 73% (442800.0 of 604800.0) |########    | Elapsed Time: 0:21:03 ETA:   0:06:19\n",
      " 73% (446400.0 of 604800.0) |########    | Elapsed Time: 0:21:11 ETA:   0:06:07\n",
      " 74% (450000.0 of 604800.0) |########    | Elapsed Time: 0:21:20 ETA:   0:05:57\n",
      " 75% (453600.0 of 604800.0) |#########   | Elapsed Time: 0:21:28 ETA:   0:05:54\n",
      " 75% (454800.0 of 604800.0) |#########   | Elapsed Time: 0:21:31 ETA:   0:05:51\n",
      " 75% (455400.0 of 604800.0) |#########   | Elapsed Time: 0:21:32 ETA:   0:05:51\n",
      " 75% (457200.0 of 604800.0) |#########   | Elapsed Time: 0:21:36 ETA:   0:05:28\n",
      " 76% (460800.0 of 604800.0) |#########   | Elapsed Time: 0:21:45 ETA:   0:05:42\n",
      " 76% (464400.0 of 604800.0) |#########   | Elapsed Time: 0:21:54 ETA:   0:05:36\n",
      " 77% (468000.0 of 604800.0) |#########   | Elapsed Time: 0:22:02 ETA:   0:05:25\n",
      " 77% (471600.0 of 604800.0) |#########   | Elapsed Time: 0:22:11 ETA:   0:05:14\n",
      " 78% (475200.0 of 604800.0) |#########   | Elapsed Time: 0:22:19 ETA:   0:05:08\n",
      " 78% (476400.0 of 604800.0) |#########   | Elapsed Time: 0:22:22 ETA:   0:05:04\n",
      " 78% (477000.0 of 604800.0) |#########   | Elapsed Time: 0:22:24 ETA:   0:05:15\n",
      " 79% (478800.0 of 604800.0) |#########   | Elapsed Time: 0:22:28 ETA:   0:04:40\n",
      " 79% (482400.0 of 604800.0) |#########   | Elapsed Time: 0:22:36 ETA:   0:04:49\n",
      " 80% (486000.0 of 604800.0) |#########   | Elapsed Time: 0:22:45 ETA:   0:04:39\n",
      " 80% (489600.0 of 604800.0) |#########   | Elapsed Time: 0:22:53 ETA:   0:04:31\n",
      " 81% (493200.0 of 604800.0) |#########   | Elapsed Time: 0:23:02 ETA:   0:04:23\n",
      " 82% (496800.0 of 604800.0) |#########   | Elapsed Time: 0:23:10 ETA:   0:04:18\n",
      " 82% (498000.0 of 604800.0) |#########   | Elapsed Time: 0:23:13 ETA:   0:04:19\n",
      " 82% (498600.0 of 604800.0) |#########   | Elapsed Time: 0:23:15 ETA:   0:04:26\n",
      " 82% (500400.0 of 604800.0) |#########   | Elapsed Time: 0:23:19 ETA:   0:03:54\n",
      " 83% (504000.0 of 604800.0) |##########  | Elapsed Time: 0:23:27 ETA:   0:04:01\n",
      " 83% (507600.0 of 604800.0) |##########  | Elapsed Time: 0:23:36 ETA:   0:03:52\n",
      " 84% (511200.0 of 604800.0) |##########  | Elapsed Time: 0:23:44 ETA:   0:03:38\n",
      " 85% (514800.0 of 604800.0) |##########  | Elapsed Time: 0:23:53 ETA:   0:03:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct cell not found after 1000000 iterations\n",
      "Correct cell not found after 1000000 iterations\n"
     ]
    },
    {
     "ename": "OutOfBoundsError",
     "evalue": "0\nParticle P[16](lon=-124.892400, lat=48.629780, depth=0.000000, decay_value=1.000000, beached=0.000000, age=0.000000, time=1207200.000000)\nTime: 2019-01-17T23:50:00.000000000,\ttimestep dt: 600.000000\nField sampled at (-124.895716, 48.631422, 0.000000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfBoundsError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_695386/274006132.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Output properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParticleFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0moutput_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m pset.execute(my_kernel,                 # the kernel (which defines how particles move)\n\u001b[0m\u001b[1;32m      4\u001b[0m              \u001b[0mruntime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# the total length of the run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# the timestep of the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda_envs/parcels-dev/lib/python3.8/site-packages/parcels/particlesets/baseparticleset.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, pyfunc, endtime, runtime, dt, moviedt, recovery, output_file, movie_background_field, verbose_progress, postIterationCallbacks, callbackdt)\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_prelease\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_movie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             self.kernel.execute(self, endtime=time, dt=dt, recovery=recovery, output_file=output_file,\n\u001b[0m\u001b[1;32m    448\u001b[0m                                 execute_once=execute_once)\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnext_prelease\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda_envs/parcels-dev/lib/python3.8/site-packages/parcels/kernel.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, pset, endtime, dt, recovery, output_file, execute_once)\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0mrecovery_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecovery_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStateCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSuccess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                     \u001b[0mrecovery_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mStateCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStateCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda_envs/parcels-dev/lib/python3.8/site-packages/parcels/tools/statuscodes.py\u001b[0m in \u001b[0;36mrecovery_kernel_out_of_bounds\u001b[0;34m(particle, fieldset, time)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOutOfBoundsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfieldset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfBoundsError\u001b[0m: 0\nParticle P[16](lon=-124.892400, lat=48.629780, depth=0.000000, decay_value=1.000000, beached=0.000000, age=0.000000, time=1207200.000000)\nTime: 2019-01-17T23:50:00.000000000,\ttimestep dt: 600.000000\nField sampled at (-124.895716, 48.631422, 0.000000)"
     ]
    }
   ],
   "source": [
    "## Output properties\n",
    "output_file = pset.ParticleFile(name= output_file_name, outputdt = timedelta(minutes = 60))\n",
    "pset.execute(my_kernel,                 # the kernel (which defines how particles move)\n",
    "             runtime=timedelta(hours = 24*7),   # the total length of the run\n",
    "             dt = timedelta(minutes = 20),      # the timestep of the kernel\n",
    "             output_file = output_file)  # the file name and the time step of the outputs\n",
    "output_file.close()\n",
    "\n",
    "plotTrajectoriesFile(output_file_name);\n",
    "\n",
    "print('particle trajectories completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "822a087f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Compiled ParcelsRandom ==> /tmp/parcels-2926/libparcels_random_715a372a-29cd-481a-bc67-8522aafbb525.so\n",
      "usage: ipykernel_launcher.py [-h] [-d DELETE_TEMPFILES] [-c PFCLASS_NAME]\n",
      "                             tempwritedir\n",
      "ipykernel_launcher.py: error: the following arguments are required: tempwritedir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlovindeer/conda_envs/parcels-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3449: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Creating a netcdf file from a partial Ocean Parcels run that was aborted because particle moved out of bounds\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from glob import glob\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# == here those classes need to be impported to parse available ParticleFile classes and create the type from its name == #\n",
    "from parcels import ParticleFile\n",
    "\n",
    "def convert_npydir_to_netcdf(tempwritedir_base, delete_tempfiles=False, pfile_class=None):\n",
    "    \"\"\"Convert npy files in tempwritedir to a NetCDF file\n",
    "    :param tempwritedir_base: directory where the directories for temporary npy files\n",
    "            are stored (can be obtained from ParticleFile.tempwritedir_base attribute)\n",
    "    \"\"\"\n",
    "\n",
    "    tempwritedir = sorted(glob(path.join(\"%s\" % tempwritedir_base, \"*\")),\n",
    "                          key=lambda x: int(path.basename(x)))[0]\n",
    "    pyset_file = path.join(tempwritedir, 'pset_info.npy')\n",
    "    if not path.isdir(tempwritedir):\n",
    "        raise ValueError('Output directory \"%s\" does not exist' % tempwritedir)\n",
    "    if not path.isfile(pyset_file):\n",
    "        raise ValueError('Output directory \"%s\" does not contain a pset_info.npy file' % tempwritedir)\n",
    "\n",
    "    pset_info = np.load(pyset_file, allow_pickle=True).item()\n",
    "    pfconstructor = ParticleFile if pfile_class is None else pfile_class\n",
    "    pfile = pfconstructor(None, None, pset_info=pset_info, tempwritedir=tempwritedir_base, convert_at_end=False)\n",
    "    pfile.close(delete_tempfiles)\n",
    "\n",
    "\n",
    "def main(tempwritedir_base=None, delete_tempfiles=False):\n",
    "    if tempwritedir_base is None:\n",
    "        p = ArgumentParser(description=\"\"\"Script to convert temporary npy output files to NetCDF\"\"\")\n",
    "        p.add_argument('tempwritedir', help='Name of directory where temporary npy files are stored '\n",
    "                                            '(not including numbered subdirectories)')\n",
    "        p.add_argument('-d', '--delete_tempfiles', default=False,\n",
    "                       help='Flag to delete temporary files at end of call (default False)')\n",
    "        p.add_argument('-c', '--pfclass_name', default='ParticleFileSOA',\n",
    "                       help='Class name of the stored particle file (default ParticleFileSOA)')\n",
    "        args = p.parse_args()\n",
    "        tempwritedir_base = args.tempwritedir\n",
    "        pfclass = ParticleFile\n",
    "        if hasattr(args, 'delete_tempfiles'):\n",
    "            delete_tempfiles = args.delete_tempfiles\n",
    "        if hasattr(args, 'pfclass_name'):\n",
    "            try:\n",
    "                pfclass = locals()[args.pfclass_name]\n",
    "            except:\n",
    "                pfclass = ParticleFile\n",
    "\n",
    "    convert_npydir_to_netcdf(tempwritedir_base, delete_tempfiles, pfile_class=pfclass)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('parcels-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4d84b090d0c7c6778fa197aacf5543338ee30c87f3fb579a323dc77be78ea57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
