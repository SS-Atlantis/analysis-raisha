{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc831756-7d59-4365-9c53-41c4978c58e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.path as mplPath\n",
    "import shapefile\n",
    "from netCDF4 import Dataset\n",
    "import dateutil.parser\n",
    "from shapely.geometry import Polygon, Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b042afee-ffe7-4f27-965b-169a51b1d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile_name = \"/ocean/rlovindeer/Atlantis/ssam_oceanparcels/SalishSea/SalishSea_July172019_2/SalishSea_July172019.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee9a58e-85af-43c6-959f-f8d3aecd87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = gpd.read_file(shapefile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c6fc666-b03b-481c-aed1-cc09da61257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numLayers = 5;\n",
    "numSites = data_df.shape[0]\n",
    "numTargetSites = numSites\n",
    "\n",
    "outputDT = 60*60 \n",
    "\n",
    "stepsPerDay = int(86400.0/ outputDT);\n",
    "numStepsPerDT = stepsPerDay;\n",
    "numStepsPerDT = int(outputDT/3600.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c232efbf-1b65-48bc-9d97-ba5511d8cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1230b41e-d8f0-4fad-b50e-ea88f05a6e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "paths = {\n",
    "    'out': './results',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a848de54-4dfa-461b-9ffb-e7560a6039b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFileName = os.path.join(paths['out'], 'Oil_disperse_2019_5b_Turn_Point_Diluted_bitumen.nc')\n",
    "\n",
    "pfile = xr.open_dataset(str(inputFileName), decode_cf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34cf01d2-8132-4b31-9a2d-465c009c0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = np.ma.filled(pfile.variables['lon'], np.nan)\n",
    "lat = np.ma.filled(pfile.variables['lat'], np.nan)\n",
    "time = np.ma.filled(pfile.variables['time'], np.nan)\n",
    "z = np.ma.filled(pfile.variables['z'], np.nan)\n",
    "probs = np.ma.filled(pfile.variables['decay_value'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb8719d-aae0-4077-bbc6-24c23252fa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-04T14:00:00.000000000\n",
      "2019-01-04T21:00:00.000000000\n",
      "2019-01-04T18:00:00.000000000\n",
      "2019-01-04T10:00:00.000000000\n",
      "2019-01-04T11:00:00.000000000\n",
      "2019-01-04T00:00:00.000000000\n",
      "2019-01-04T02:00:00.000000000\n",
      "2019-01-04T15:00:00.000000000\n",
      "2019-01-04T04:00:00.000000000\n",
      "2019-01-04T03:00:00.000000000\n",
      "2019-01-04T12:00:00.000000000\n",
      "2019-01-04T16:00:00.000000000\n",
      "2019-01-04T17:00:00.000000000\n",
      "2019-01-04T21:00:00.000000000\n",
      "2019-01-04T06:00:00.000000000\n",
      "2019-01-04T12:00:00.000000000\n",
      "2019-01-04T19:00:00.000000000\n",
      "2019-01-04T16:00:00.000000000\n",
      "2019-01-04T22:00:00.000000000\n",
      "2019-01-04T05:00:00.000000000\n",
      "2019-01-04T01:00:00.000000000\n",
      "2019-01-04T00:00:00.000000000\n",
      "2019-01-04T01:00:00.000000000\n",
      "2019-01-04T00:00:00.000000000\n",
      "2019-01-04T13:00:00.000000000\n",
      "2019-01-04T13:00:00.000000000\n",
      "2019-01-04T13:00:00.000000000\n",
      "2019-01-04T12:00:00.000000000\n",
      "2019-01-04T02:00:00.000000000\n",
      "2019-01-04T22:00:00.000000000\n",
      "2019-01-04T19:00:00.000000000\n",
      "2019-01-04T22:00:00.000000000\n",
      "2019-01-04T03:00:00.000000000\n",
      "2019-01-04T14:00:00.000000000\n",
      "2019-01-04T13:00:00.000000000\n",
      "2019-01-04T21:00:00.000000000\n",
      "2019-01-04T12:00:00.000000000\n",
      "2019-01-04T22:00:00.000000000\n",
      "2019-01-04T08:00:00.000000000\n",
      "2019-01-04T16:00:00.000000000\n",
      "2019-01-04T01:00:00.000000000\n",
      "2019-01-04T18:00:00.000000000\n",
      "2019-01-04T08:00:00.000000000\n",
      "2019-01-04T20:00:00.000000000\n",
      "2019-01-04T10:00:00.000000000\n",
      "2019-01-04T20:00:00.000000000\n",
      "2019-01-04T04:00:00.000000000\n",
      "2019-01-04T08:00:00.000000000\n",
      "2019-01-04T11:00:00.000000000\n",
      "2019-01-04T04:00:00.000000000\n",
      "2019-01-04T02:00:00.000000000\n",
      "2019-01-04T13:00:00.000000000\n",
      "2019-01-04T04:00:00.000000000\n",
      "2019-01-04T01:00:00.000000000\n",
      "2019-01-04T18:00:00.000000000\n",
      "2019-01-04T20:00:00.000000000\n",
      "2019-01-04T22:00:00.000000000\n",
      "2019-01-04T18:00:00.000000000\n",
      "2019-01-04T22:00:00.000000000\n",
      "2019-01-04T18:00:00.000000000\n",
      "2019-01-04T02:00:00.000000000\n",
      "2019-01-04T01:00:00.000000000\n",
      "2019-01-04T08:00:00.000000000\n",
      "2019-01-04T07:00:00.000000000\n",
      "2019-01-04T16:00:00.000000000\n",
      "2019-01-04T18:00:00.000000000\n",
      "2019-01-04T21:00:00.000000000\n",
      "2019-01-04T19:00:00.000000000\n",
      "2019-01-04T21:00:00.000000000\n",
      "2019-01-04T19:00:00.000000000\n",
      "2019-01-04T08:00:00.000000000\n",
      "2019-01-04T12:00:00.000000000\n",
      "2019-01-04T01:00:00.000000000\n",
      "2019-01-04T02:00:00.000000000\n",
      "2019-01-04T16:00:00.000000000\n",
      "2019-01-04T17:00:00.000000000\n",
      "2019-01-04T02:00:00.000000000\n",
      "2019-01-04T02:00:00.000000000\n",
      "2019-01-04T22:00:00.000000000\n",
      "2019-01-04T22:00:00.000000000\n",
      "2019-01-04T16:00:00.000000000\n",
      "2019-01-04T09:00:00.000000000\n",
      "2019-01-04T06:00:00.000000000\n",
      "2019-01-04T08:00:00.000000000\n",
      "2019-01-04T19:00:00.000000000\n",
      "2019-01-04T08:00:00.000000000\n",
      "2019-01-04T13:00:00.000000000\n",
      "2019-01-04T00:00:00.000000000\n",
      "2019-01-04T05:00:00.000000000\n",
      "2019-01-04T14:00:00.000000000\n",
      "2019-01-04T05:00:00.000000000\n",
      "2019-01-04T07:00:00.000000000\n",
      "2019-01-05T00:00:00.000000000\n",
      "2019-01-04T11:00:00.000000000\n",
      "2019-01-04T22:00:00.000000000\n",
      "2019-01-04T18:00:00.000000000\n",
      "2019-01-04T12:00:00.000000000\n",
      "2019-01-04T18:00:00.000000000\n",
      "2019-01-04T17:00:00.000000000\n",
      "2019-01-04T17:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "numParticles = lon.shape[0]\n",
    "\n",
    "trackDates = [];\n",
    "\n",
    "for i in range(0,numParticles):\n",
    "    print(time[i][0])\n",
    "    #trackDates.append( dateutil.parser.parse(time[i][0]))\n",
    "    trackDates.append(time[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95c6c9ad-dd4d-4bfb-86cf-44507546ed2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-04 00:30:00\n"
     ]
    }
   ],
   "source": [
    "RDiff = max(trackDates) - min(trackDates)\n",
    "\n",
    "minDate = np.datetime64(\"2019-01-04T00:30:00\");\n",
    "ts = pd.to_datetime(str(minDate))\n",
    "d = ts.strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e3f88d0-6920-4299-b5a2-252b45254866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trackLength = 145\n",
      "numStepsPerDT = 1\n"
     ]
    }
   ],
   "source": [
    "numReleaseDays = 1;\n",
    "numReleaseSteps = numReleaseDays * stepsPerDay;\n",
    "trackLength = len(lon[0]);\n",
    "\n",
    "print('trackLength = ' + str(trackLength))\n",
    "print('numStepsPerDT = ' + str(numStepsPerDT))\n",
    "\n",
    "numSteps = int(trackLength / numStepsPerDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c24648a1-8ef8-4a61-82cd-ea8fce6a77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the netcdf output file\n",
    "\n",
    "netcdfFileName = \"Atlantis_Oil_2019\" + \"_dt_\" + str(outputDT) + \".nc\"\n",
    "\n",
    "try:\n",
    "    os.remove(netcdfFileName)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "ncfile = Dataset(netcdfFileName, \"w\", format=\"NETCDF4\", clobber=True)\n",
    "\n",
    "# Dimensions\n",
    "time = ncfile.createDimension(\"t\", None)\n",
    "b = ncfile.createDimension(\"b\", numTargetSites)\n",
    "z = ncfile.createDimension(\"z\", numLayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1fe9a30-69b6-44e8-8030-a8b6d1b6dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "times = ncfile.createVariable(\"time\",\"f4\",(\"t\",))\n",
    "oil = ncfile.createVariable(\"oil\",\"f4\",(\"t\", \"b\",))\n",
    "Naphthalene = ncfile.createVariable(\"Naphthalene\",\"f4\",(\"t\", \"b\",))\n",
    "Phenanthrene = ncfile.createVariable(\"Phenanthrene\",\"f4\",(\"t\", \"b\",))\n",
    "Pyrene = ncfile.createVariable(\"Pyrene\",\"f4\",(\"t\", \"b\",))\n",
    "Benzo = ncfile.createVariable(\"Benzo\",\"f4\",(\"t\", \"b\",))\n",
    "\n",
    "# Attributes\n",
    "times.units = \"seconds since \" + d\n",
    "times.dt = str(outputDT);\n",
    "oil.units = \"mgPAH/m^3\"\n",
    "\n",
    "Naphthalene.units = \"mgPAH/m^3\"\n",
    "Naphthalene.long_name = \"Amount of Naphthalene\"\n",
    "\n",
    "Phenanthrene.units = \"mgPAH/m^3\"\n",
    "Phenanthrene.long_name = \"Amount of Phenanthrene\"\n",
    "\n",
    "Pyrene.units = \"mgPAH/m^3\"\n",
    "Pyrene.long_name = \"Amount of Pyrene\"\n",
    "\n",
    "Benzo.units = \"mgPAH/m^3\"\n",
    "Benzo.long_name = \"Amount of Benzo(a)pyrene\"\n",
    "\n",
    "# Populate variables with data\n",
    "timeData = np.arange(0,(numSteps + numReleaseSteps)*outputDT,outputDT)\n",
    "times[:] = timeData;\n",
    "\n",
    "boxDispersal = np.zeros((numSteps + numReleaseSteps, numTargetSites));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7252d1a5-49f2-4472-b58b-150457b79de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partIndex in range(0, numParticles):\n",
    "\n",
    "    trackDateDiff = trackDates[partIndex] - minDate;\n",
    "    trackDateDiff = trackDateDiff/ np.timedelta64(1, 's')\n",
    "\n",
    "    timeOffset = int(abs((trackDateDiff /outputDT)));\n",
    "\n",
    "    for stepIndex in range(0, numSteps):\n",
    "        timeValue = stepIndex + timeOffset\n",
    "\n",
    "        partLon = lon[partIndex][stepIndex * numStepsPerDT];\n",
    "        partLat = lat[partIndex][stepIndex * numStepsPerDT];\n",
    "        partProb = probs[partIndex][stepIndex * numStepsPerDT];\n",
    "\n",
    "        matchFound = 0;\n",
    "\n",
    "        for targetIndex in range(0, numTargetSites):\n",
    "\n",
    "            path = data_df.iloc[targetIndex].geometry\n",
    "            checks = path.contains(Point(partLon, partLat));\n",
    "\n",
    "            if checks:\n",
    "                boxDispersal[timeValue][targetIndex] = boxDispersal[timeValue][targetIndex] + partProb;\n",
    "\n",
    "                # uncomment line below to ignore particle decay during debugging.\n",
    "                #boxDispersal[timeValue][targetIndex] = boxDispersal[timeValue][targetIndex] + 1.0\n",
    "\n",
    "                matchFound = 1\n",
    "                if debug:\n",
    "                    print('At time ' + str(timeValue) + ' Particle (' + str(partIndex) + ') in box ' + str(data_df.iloc[targetIndex].BOX_ID))\n",
    "\n",
    "\n",
    "                break;\n",
    "\n",
    "        if matchFound == 0:\n",
    "            if debug:\n",
    "                print('No match for particle')\n",
    "                print(partLon, partLat)\n",
    "\n",
    "\n",
    "        #break\n",
    "\n",
    "oil[:, :] = boxDispersal;\n",
    "Naphthalene[:, :] = boxDispersal;\n",
    "Phenanthrene[:, :] = boxDispersal;\n",
    "Pyrene[:, :] = boxDispersal;\n",
    "Benzo[:, :] = boxDispersal;\n",
    "\n",
    "ncfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec6ab6-ab30-46d1-b068-626e0dbf3892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
